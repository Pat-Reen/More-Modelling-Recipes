[
  {
    "path": "posts/2022-02-01-bayesian-applications/",
    "title": "Bayesian applications",
    "description": "Bayesian refresher, regression models and other applications.",
    "author": [
      {
        "name": "Pat Reen",
        "url": "https://www.linkedin.com/in/patrick-reen/"
      }
    ],
    "date": "2022-02-01",
    "categories": [
      "bayesian",
      "statistics",
      "regression"
    ],
    "contents": "\r\n\r\nContents\r\nBackground\r\nApplications\r\nLibraries\r\nMental health example\r\nChoosing a prior\r\nDeriving posterior\r\n\r\nRegression - logistic\r\nBackground\r\nHeart disease data\r\nAdjusting scales and changing priors\r\nModel fit\r\n\r\nRegression - linear\r\nEstimating COVID 19 infections in NSW, Australia\r\n\r\nCommon issues in MCMC projections\r\nFurther reading\r\n\r\nBackground\r\nBayesian statistics reflects uncertainty about model parameters by assuming some prior probability distribution for those parameters. That prior uncertainty is adjusted for observed data to produce a posterior distribution.\r\nUnder a frequentest approach, model parameters are fixed and the observations are assumed to be sampled from a probability distribution with those parameters.\r\nBayes theorem refresher:\r\n\\(\\Huge {p}(\\theta,x) = \\frac{{p}(x,\\theta){p}(\\theta)}{{p}(x)}\\)\r\nWhere\r\n\\({p}(\\theta,x)\\) is the posterior, a combination of the likelihood, prior and evidence. Probability distribution of \\(\\theta\\) given the observed data, \\(x\\).\r\n\\({p}(x,\\theta)\\) is the likelihood which summarizes the likelihood of observing data \\(x\\) under different values of the underlying support parameter \\(\\theta\\).\r\n\\({p}(\\theta)\\) is the prior, the probability distribution of \\(\\theta\\), independent of the observed data.\r\n\\({p}(x)\\) is the evidence (normalising term), the probability of the observed data \\(x\\), independent of \\(\\theta\\).\r\nThe evidence term is proportional to the likelihood and therefore the theorem is often stated as\r\n\\(\\Huge p(\\theta | x) \\propto p(x | \\theta) p(\\theta)\\)\r\nA paper presented at the 2021 Actuaries (Institute) Summit Hugh Miller, Isabella Lyons (2012) (p2) sets out the ‘tensions’ that exist between Frequentest and Bayesian approaches and suggests that:\r\n\r\n“Despite actuaries being pioneers in early work on credibility theory, Bayesian approaches have largely given way to frequentist approaches. This is to our loss, since such methods have advanced substantially over the past couple of decades and they are well-suited to problems with latent variables or noise around underlying ‘true’ values.”\r\n\r\nHere we’ll look at a few simple applications of Bayesian techniques.\r\nApplications\r\nThe sections below set out a simple example Bayesian refresher, regression models and other applications.\r\nLibraries\r\nA list of packages used in the recipes.\r\nMental health example\r\nThe 2017 Actuaries Institute Green Paper on Mental Health and Insurance “Mental Health and Insurance” (2017) talks about some of the challenges in obtaining reliable data and projections on mental health in insurance (“Mental Health and Insurance” 2017, p26):\r\n\r\n\"There are sources of data and research about the prevalence and profile of people with different mental health conditions, such as the 2007 National Survey of Mental Health and Wellbeing and many other epidemiological and clinical studies… [T]o have a complete and informed view of all this information is a difficult task for a full-time academic, let alone for an insurer.\r\nEven then, the nature and granularity of the data needed for insurance applications is different from that for population, public health or clinical purposes. Firstly, the ‘exposure’ (the number of insured people and their characteristics) needs to be recorded. There is probably a lot of relevant information that is not collected at the start of an insurance policy and can therefore never be analysed.\r\nSecondly, the claims information needs to be available at a detailed level regarding the nature and cause of the claim and other characteristics of the individual, their history and the cover provided. There is a clear need for consistency in definition, language and data standards to improve the quality of information available across the system.\r\nNaturally, when the insurance cover for mental health conditions is not provided (as in the case of most travel insurance products) there will not be relevant data from the insurance history. However, even when relevant data exists within insurers there are practical and commercial difficulties in turning it into a useful form.\"\r\n\r\nThe paper goes on to talk about some of the insurance challenges in detail including\r\nsubjectivity in diagnosis\r\nreliance on self-reporting\r\nvarying severity and prospects of recovery\r\nimpact of co-morbidities\r\ncorrelation with financial incentive\r\nBased upon data from a single insurer ~19% of TP and TPD claims relate to mental health, with mental health claims contributing 26% to the total cost of claims (in 2015, “Mental Health and Insurance” (2017), p17). This is roughly consistent with the proportion of the general population that experiences an episode of mental illness in a 12 month period, “Mental Health and Insurance” (2020), p110.\r\nIn this simple example, we want to know what the rate of mental illness, \\(\\theta\\) is in the insured population. Assume some true underlying \\(\\theta\\), here a fixed value of 20%. Create a population, \\(X\\) with \\(X \\sim B(N,\\theta)\\) where N=100000. Pull a random sample from population.\r\n\r\n\r\nShow code\r\n\r\ntheta_true <- 0.2 \r\npop <- rbinom(100000,1,theta_true)\r\nsample_n = 500\r\nsample <- sample(pop,sample_n)\r\nsample_success <- sum(sample)\r\nsample_p <- sample_success/sample_n\r\n\r\n\r\n\r\nChoosing a prior\r\nThe posterior is proportional to the product of the prior and the likelihood. The beta distribution is a conjugate prior for the binomial distribution (posterior is the same probability distribution family as prior). Assume \\(\\theta \\sim {\\sf Beta}(\\alpha, \\beta)\\), then:\r\n\\(f(\\theta;\\alpha,\\beta) = \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\\)\r\nIt represents the probabilities assigned to values of \\(\\theta\\) in the domain (0,1) given values for the parameters \\(\\alpha\\) and \\(\\beta\\). The binomial posterior distribution represents the probability of values of \\(X\\) given \\(\\theta\\). Varying the values of \\(\\alpha\\) and \\(\\beta\\) can represent a wide range of different prior beliefs about the distribution of \\(\\theta\\).\r\nPriors can be “informative” “uninformative” or “weakly informative,” e.g. \r\nnon-informative - uniform dist => \\(\\theta\\) could be anywhere in (0,1)\r\nweakly informative uniform prior => believe \\(\\theta\\) more likely to be at either end of the ranges (less likely to be in the middle)\r\nstrongly informative prior\r\na and b both high (bimodial) => true theta likely to be at center of range\r\na higher than b (strong “success”) => success more likely than failure (where “success” is a mental health claim)\r\nb higher than a (strong “failure”) => failure more likely than success\r\n\r\nDefining prior plots:\r\n\r\n\r\nShow code\r\n\r\nplot_prior <- function(a,b){\r\n  theta = seq(0,1,0.005)\r\n  p_theta = dbeta(theta, a, b)\r\n  p <- qplot(theta, p_theta, geom='line')\r\n  p <- p + theme_bw()\r\n  p <- p + ylab(expression(paste('p(',theta,')', sep = '')))\r\n  p <- p + xlab(expression(theta))\r\n  return(p)}\r\n\r\n\r\n\r\nNon-informative prior, uniform\r\n\r\n\r\nShow code\r\n\r\nplot_prior(1,1) + labs(title=\"Uniform Prior, a= 1 and b = 1\") + theme(plot.title = element_text(hjust = 0.5))\r\n\r\n\r\n\r\n\r\nWeakly informative prior, bimodial\r\n\r\n\r\nShow code\r\n\r\nplot_prior(0.5,0.5) + labs(title=\"Bimodial Prior, a= 0.5 and b = 0.5\") + theme(plot.title = element_text(hjust = 0.5))\r\n\r\n\r\n\r\n\r\nInformative prior, “failure” more likely\r\nThe higher the number of observations, the greater the influence on the posterior\r\n\r\n\r\nShow code\r\n\r\nplot_prior(5,30) + labs(title=\"Uniform Prior, a= 5 and b = 30\") + theme(plot.title = element_text(hjust = 0.5))\r\n\r\n\r\n\r\nShow code\r\n\r\nplot_prior(20,120) + labs(title=\"Uniform Prior, a= 20 and b = 120\") + theme(plot.title = element_text(hjust = 0.5))\r\n\r\n\r\n\r\n\r\nDeriving posterior\r\nPrior plot values. Re-express binomial as beta dist.\r\n\r\n\r\nShow code\r\n\r\n  prior_a = 50 #successes\r\n  prior_b = 250 #failures\r\n  prior_n = prior_a + prior_b #observations\r\n  prior_theta = prior_a/prior_n\r\n  prior <- data.frame('Dist'='Prior','x'=seq(0,1,0.005), 'y'=dbeta(seq(0,1,0.005),prior_a,prior_b))\r\n\r\n\r\n\r\nObservations are taken from the earlier binomial sample.\r\n\r\n\r\nShow code\r\n\r\n  obs_a <- sample_success + 1\r\n  obs_b <- sample_n - sample_success + 1\r\n  observations <- data.frame('Dist'='Observations',x=seq(0,1,0.005), y=dbeta(seq(0,1,0.005),obs_a,obs_b))\r\n\r\n\r\n\r\nIn this example, the posterior is a simple combination of the prior and observations.\r\n\r\n\r\nShow code\r\n\r\n  post_a <- sample_success + prior_a - 1 #combination of prior and observed successes\r\n  post_b <- sample_n - sample_success + prior_b - 1\r\n  post_theta <- post_a / (post_a + post_b)\r\n  posterior <- data.frame('Dist'='Posterior','x'=seq(0,1,0.005), 'y'=dbeta(seq(0,1,0.005),post_a,post_b))\r\n\r\n\r\n\r\nThis can be plotted as:\r\n\r\n\r\nShow code\r\n\r\nmodel_plot <- rbind(prior,observations,posterior)\r\nwith(model_plot, Dist <- factor(Dist, levels = c('Prior', 'Observations','Posterior'), ordered = TRUE))\r\n\r\nqplot(model_plot$x, model_plot$y, geom='line',color = model_plot$Dist) +\r\nylab(expression(paste('p(',theta,')', sep = ''))) +\r\nxlab(expression(theta)) +\r\ngeom_vline(xintercept = post_theta, linetype=\"dotted\", color = \"black\", label=\"blah\") +\r\nscale_color_discrete(name = \"Dist\")  + \r\nannotate(\"text\",x=post_theta, y=0, label=label_percent()(post_theta)) +\r\nlabs(title=\"Informative prior\", subtitle=\"Low success\") + \r\ntheme(plot.title = element_text(hjust = 0.5)) +\r\ntheme(plot.subtitle = element_text(hjust = 0.5))\r\n\r\n\r\n\r\n\r\nRegression - logistic\r\nBackground\r\nRSTANARM is an interface in R for STAN where Stan is a platform for Bayesian inference - it is a probabilistic programming framework where the guts of the inference method happens in the background, while the user focuses on parameterising the model in R. RJAGS is an interface in R for JAGS (Just Another Gibbs Sample) where JAGS is similarly a platform for Bayesian modeling.\r\nModels in both STAN and JAGS can make use of Markov chains Monte Carlo (MCMC) methods. MCMC methods provide a way to take random samples approximately from a posterior distribution. Such samples can be used to summarize any aspect of the posterior distribution of a statistical model.\r\nRSTANARM and RJAGS have pre-written code for common models like regression.\r\nUnder a Frequentest approach to linear regression, for a given set of response variables y, the relationship between y and a set of regressor variables x is assumed to be linear (informed by a set of parameters \\(\\beta\\)), with an error term, i.e. \\(y = X\\beta + \\epsilon\\).\r\nThe error term, \\(\\epsilon\\) is assumed to be normally distributed and the regression co-efficients are estimated by minimising the error term commonly using ordinary least squares (OLS). We make some other assumptions about the error term - not correlated with X and i.i.d.; and define \\(Var(\\epsilon)=\\sigma^2\\). The generalised form allows the response variable to have an error that is not normal - this is achieved by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\r\nWith Bayesian inference we are interested in the posterior distributions of the parameters \\(\\beta\\) and \\(\\sigma\\), rather than point estimates. We also want to influence those distributions with some prior knowledge of their behaviour:\r\n\\(p(\\beta,\\sigma|y,X) \\propto p(y|\\beta,\\sigma)p(\\beta,\\sigma)\\)\r\n\\(p(\\beta,\\sigma|y,X)\\) is not a normalised probability density function (i.e. is proportional to the likelihood and prior). However, we can sample from it and therefore estimate any quantity of interest e.g. mean or variance, (William H. Press 2007, p825). For this we use MCMC, William H. Press (2007), p825:\r\n\r\n“MCMC is a random sampling method… the goal is to visit a point \\(x\\) with a probability proportional to some given distribution function \\(\\pi(x)\\) [not necessarily a probability]. Why would we want to sample a distribution in this way? THe answer is that Bayesian methods, often implemented using MCMC, provide a powerful way of estimating the parameters of a model and their degree of uncertainty.”\r\n\r\nHeart disease data\r\nThe Framingham Heart Study is a longitudinal study of cardiovastular disease in a sample population within Framingham, Massachusetts. A subset of data for teaching is available at request from the U.S. National Heart, Lung and Blood Institute. This dataset is not appropriate for publication and has been anonymised, but is nevertheless useful for illustrative purposes here. The dataset:\r\n\r\n“..is a subset of the data collected as part of the Framingham study and includes laboratory, clinic, questionnaire, and adjudicated event data on 4,434 participants. Participant clinic data was collected during three examination periods, approximately 6 years apart, from roughly 1956 to 1968. Each participant was followed for a total of 24 years for the outcome of the following events: Angina Pectoris, Myocardial Infarction, Atherothrombotic Infarction or Cerebral Hemorrhage (Stroke) or death.”\r\n\r\nWe’ll look at a logistic regression model example using predefined Bayesian models in RSTANARM.\r\n\r\n\r\nShow code\r\n\r\ndf_heart <- read.csv(file = 'frmgham2.csv') \r\ndf_heart <- df_heart[c(1:23)] %>% filter(PERIOD==2) # ignoring health event data, only looking at observations at period == 2 (observations for participants are not independent over time; this does have limitations e.g. observations are truncated at death which could be due to heart disease)\r\nignore_cols <- names(df_heart) %in% c(\"PERIOD\",\"RANDID\",\"TIME\", \"PREVMI\", \"PREVAP\") #exclude identifier and time columns; exclude  PREVMI and PREVAP as they are a subset of PREVCHD\r\ndf_heart <- df_heart[!ignore_cols]\r\nhead(df_heart)\r\n\r\n\r\n  SEX TOTCHOL AGE SYSBP DIABP CURSMOKE CIGPDAY   BMI DIABETES BPMEDS\r\n1   2     260  52   105  69.5        0       0 29.43        0      0\r\n2   1     283  54   141  89.0        1      30 25.34        0      0\r\n3   2     232  67   183 109.0        1      20 30.18        0      0\r\n4   2     343  51   109  77.0        1      30 23.48        0      0\r\n5   2     230  49   177 102.0        0       0 31.36        0      1\r\n6   2     220  70   149  81.0        0       0 36.76        0      0\r\n  HEARTRTE GLUCOSE educ PREVCHD PREVSTRK PREVHYP HDLC LDLC\r\n1       80      86    2       0        0       0   NA   NA\r\n2       75      87    1       0        0       0   NA   NA\r\n3       60      89    3       0        0       1   NA   NA\r\n4       90      72    3       0        0       0   NA   NA\r\n5      120      86    2       0        0       1   NA   NA\r\n6       80      98    1       1        0       1   NA   NA\r\n\r\nData description highlights:\r\nRANDIND: unique identifier.\r\nSEX: 1=male; 2=female (categorical, 1/2).\r\nTIME: number of days since baseline exam (continuous).\r\nPERIOD: examination cycle (categorical, 1,2 or 3). We’ll focus on period 2 - observations for the same participant are not independent over time.\r\nTOTCHOL: total cholesterol level (continuous).\r\nAGE: Age of the patient rounded to nearest year (continuous).\r\nSYSBP: systolic blood pressure (continuous).\r\nDIABP: diastolic blood pressure (continuous).\r\nCURSMOKE: whether or not the patient is a current smoker (categorical, 0/1).\r\nCIGPDAY: the number of cigarettes smoked per day on average (continuous).\r\nBMI: Body Mass Index (continuous).\r\nDIABETES: whether or not the patient had diabetes (categorical, 0/1).\r\nBPMEDS: whether or not the patient was on blood pressure medication (categorical, 0/1).\r\nHEARTRTE: heart rate (continuous).\r\nGLUCOSE: glucose level (continuous).\r\nEDU: attained Education (categorical, 1=0-11 year; 2=High School Diploma, GED; 3=Some College, Vocational School; 4=College (BS, BA) degree or more).\r\nHDLC: High Density Lipoprotein Cholesterol - only available for period 3 (continuous).\r\nLDLC: Low Density Lipoprotein Cholesterol - only available for period 3 (continuous).\r\nPREVCHD: prevalence of Coronary Heart Disease (categorical, 0/1).\r\nPREVAP: prevalence of Angina Pectoris (categorical, 0/1). Excluded from model as it is a subset of PREVCHD.\r\nPREVMI: Prevalence of Myocardial Infarction (categorical, 0/1). Excluded from model as it is a subset of PREVCHD.\r\nPREVSTRK: whether or not the patient had previously had a stroke (categorical, 0/1).\r\nPREVHYP: whether or not the patient was hypertensive (categorical, 0/1).\r\nUsing the DataExplore package, we can see that the data is mostly complete apart from missing entries in ‘glucose’ and to a lesser extent ‘education.’\r\n\r\n\r\nShow code\r\n\r\nintroduce(df_heart)\r\n\r\n\r\n  rows columns discrete_columns continuous_columns\r\n1 3930      18                0                 16\r\n  all_missing_columns total_missing_values complete_rows\r\n1                   2                 8720             0\r\n  total_observations memory_usage\r\n1              70740       334464\r\n\r\nShow code\r\n\r\nplot_intro(df_heart)\r\n\r\n\r\n\r\nShow code\r\n\r\nplot_missing(df_heart)\r\n\r\n\r\n\r\n\r\nGiven around 12% of glucose records are missing as well as all of HDL and LDL (only available for period 3), drop the columns. Also drop rows with other missing data as these are small in number.\r\n\r\n\r\nShow code\r\n\r\ndf_heart$GLUCOSE <- NULL\r\ndf_heart$HDLC <- NULL\r\ndf_heart$LDLC <- NULL\r\ndf_heart <- na.omit(df_heart)\r\n\r\n\r\n\r\nPlots of the data:\r\n\r\n\r\nShow code\r\n\r\nplot_bar(df_heart, title=\"Barplot\")\r\n\r\n\r\n\r\n\r\nOf the 3.6k remaining records, ~7% have a flag for heart disease:\r\n\r\n\r\nShow code\r\n\r\ntable(df_heart$PREVCHD)\r\n\r\n\r\n\r\n   0    1 \r\n3319  253 \r\n\r\nFurther plots and checking distributions:\r\n\r\n\r\nShow code\r\n\r\nplot_histogram(df_heart, title=\"Histogram for continuous\")\r\n\r\n\r\n\r\nShow code\r\n\r\nqq_data <- df_heart[,c(\"BMI\", \"DIABP\", \"HEARTRTE\", \"SYSBP\", \"TOTCHOL\")]\r\nplot_qq(qq_data, title=\"QQ plot\")\r\n\r\n\r\n\r\nShow code\r\n\r\nlog_qq_data <- update_columns(qq_data, 2:4, function(x) log(x + 1))\r\nplot_qq(log_qq_data, title=\"QQ plot, logged data\")\r\n\r\n\r\n\r\n\r\nMost significantly correlated with heart disease are AGE, SYSBP, DIABETES, BPMEDS and PREVHYP.\r\n\r\n\r\nShow code\r\n\r\nplot_correlation(na.omit(df_heart))\r\n\r\n\r\n\r\n\r\nSplit data into training and testing data sets.\r\n\r\n\r\nShow code\r\n\r\n# Create a random sample of row IDs\r\nsample_rows <- sample(nrow(df_heart),0.75*nrow(df_heart))\r\n# Create the training dataset\r\ndf_heart_train <- df_heart[sample_rows,]\r\n# Create the test dataset\r\ndf_heart_test <- df_heart[-sample_rows,]\r\n\r\n\r\n\r\nFit a simple GLM using all data:\r\n\r\n\r\nShow code\r\n\r\nfull_model_glm <- glm(PREVCHD~.,data=df_heart_train, family = \"binomial\")\r\nsummary(full_model_glm)\r\n\r\n\r\n\r\nCall:\r\nglm(formula = PREVCHD ~ ., family = \"binomial\", data = df_heart_train)\r\n\r\nDeviance Residuals: \r\n    Min       1Q   Median       3Q      Max  \r\n-1.2775  -0.3968  -0.2656  -0.1757   2.9691  \r\n\r\nCoefficients:\r\n             Estimate Std. Error z value Pr(>|z|)    \r\n(Intercept) -6.313949   1.288465  -4.900 9.57e-07 ***\r\nSEX         -1.089940   0.182660  -5.967 2.42e-09 ***\r\nTOTCHOL      0.004530   0.001754   2.582  0.00982 ** \r\nAGE          0.076020   0.011753   6.468 9.93e-11 ***\r\nSYSBP        0.007092   0.005149   1.377  0.16837    \r\nDIABP       -0.014667   0.009938  -1.476  0.13999    \r\nCURSMOKE     0.197805   0.261556   0.756  0.44949    \r\nCIGPDAY     -0.007766   0.011165  -0.696  0.48672    \r\nBMI          0.024037   0.020648   1.164  0.24437    \r\nDIABETES     0.800575   0.282443   2.834  0.00459 ** \r\nBPMEDS       0.387850   0.238491   1.626  0.10389    \r\nHEARTRTE    -0.012072   0.006753  -1.788  0.07385 .  \r\neduc        -0.103730   0.084146  -1.233  0.21767    \r\nPREVSTRK    -0.012886   0.652559  -0.020  0.98424    \r\nPREVHYP      0.495816   0.224508   2.208  0.02721 *  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n(Dispersion parameter for binomial family taken to be 1)\r\n\r\n    Null deviance: 1303.9  on 2678  degrees of freedom\r\nResidual deviance: 1133.4  on 2664  degrees of freedom\r\nAIC: 1163.4\r\n\r\nNumber of Fisher Scoring iterations: 6\r\n\r\nUse stepwise regression to reduce the explanatory variables:\r\n\r\n\r\nShow code\r\n\r\n# specify a null model with no predictors\r\nnull_model_glm <- glm(PREVCHD ~ 1, data = df_heart_train, family = \"binomial\")\r\n# use a forward stepwise algorithm to build a parsimonious model\r\nstep_model_glm <- step(null_model_glm, scope = list(lower = null_model_glm, upper = full_model_glm), direction = \"forward\")\r\n\r\n\r\n\r\nSummary of the model:\r\n\r\n\r\nShow code\r\n\r\nsummary(step_model_glm)\r\n\r\n\r\n\r\nCall:\r\nglm(formula = PREVCHD ~ AGE + SEX + PREVHYP + DIABETES + TOTCHOL + \r\n    HEARTRTE + BPMEDS + educ, family = \"binomial\", data = df_heart_train)\r\n\r\nDeviance Residuals: \r\n    Min       1Q   Median       3Q      Max  \r\n-1.2298  -0.3993  -0.2652  -0.1755   2.9466  \r\n\r\nCoefficients:\r\n             Estimate Std. Error z value Pr(>|z|)    \r\n(Intercept) -6.240633   0.933578  -6.685 2.31e-11 ***\r\nAGE          0.082205   0.010606   7.750 9.16e-15 ***\r\nSEX         -1.034461   0.176155  -5.872 4.29e-09 ***\r\nPREVHYP      0.538185   0.189374   2.842 0.004484 ** \r\nDIABETES     0.915560   0.276707   3.309 0.000937 ***\r\nTOTCHOL      0.004439   0.001750   2.536 0.011198 *  \r\nHEARTRTE    -0.013126   0.006639  -1.977 0.048029 *  \r\nBPMEDS       0.419879   0.231956   1.810 0.070271 .  \r\neduc        -0.125905   0.082751  -1.521 0.128137    \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n(Dispersion parameter for binomial family taken to be 1)\r\n\r\n    Null deviance: 1303.9  on 2678  degrees of freedom\r\nResidual deviance: 1137.6  on 2670  degrees of freedom\r\nAIC: 1155.6\r\n\r\nNumber of Fisher Scoring iterations: 6\r\n\r\nDropping BPMEDS, HEARTRTE and BMI as little impact on AIC:\r\n\r\n\r\nShow code\r\n\r\nfinal_model_glm <- glm(PREVCHD ~ AGE + SEX + PREVHYP + DIABETES + TOTCHOL, family = \"binomial\",data = df_heart_train)\r\nsummary(final_model_glm)\r\n\r\n\r\n\r\nCall:\r\nglm(formula = PREVCHD ~ AGE + SEX + PREVHYP + DIABETES + TOTCHOL, \r\n    family = \"binomial\", data = df_heart_train)\r\n\r\nDeviance Residuals: \r\n    Min       1Q   Median       3Q      Max  \r\n-1.1777  -0.4060  -0.2705  -0.1810   2.9478  \r\n\r\nCoefficients:\r\n             Estimate Std. Error z value Pr(>|z|)    \r\n(Intercept) -7.712317   0.760024 -10.147  < 2e-16 ***\r\nAGE          0.086480   0.010409   8.308  < 2e-16 ***\r\nSEX         -1.006858   0.172141  -5.849 4.94e-09 ***\r\nPREVHYP      0.580990   0.179689   3.233  0.00122 ** \r\nDIABETES     0.887841   0.273721   3.244  0.00118 ** \r\nTOTCHOL      0.004345   0.001753   2.479  0.01318 *  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n(Dispersion parameter for binomial family taken to be 1)\r\n\r\n    Null deviance: 1303.9  on 2678  degrees of freedom\r\nResidual deviance: 1147.3  on 2673  degrees of freedom\r\nAIC: 1159.3\r\n\r\nNumber of Fisher Scoring iterations: 6\r\n\r\nFit a Bayes glm using the same explanatory variables. Here parameter estimates no longer have test statistics and p-values as in the frequentist regression. This is because Bayesian estimation samples from the posterior distribution. This means that instead of a point estimate and a test statistic, we get a distribution of plausible values for the parameters, and the estimates section of the summary summarizes those distributions.\r\nFurther documentation on Bayesian generalised linear models via Stan is here. Documentation on choice of priors is here. If priors are not specified, default weekly informative priors are used - you can call a summary of the modeled priors (see below). Default priors are autoscaled to make them less informative (see below for notes on scaling).\r\n\r\n\r\nShow code\r\n\r\nmodel_bayes_glm <- stan_glm(PREVCHD ~ AGE + SEX + PREVHYP + DIABETES + TOTCHOL, family = \"binomial\",data=df_heart_train, iter=2000, warmup=500)\r\n# chains is number of sample paths from posterior; iter is number of samples within a chain; warmup is number of iterations to discard\r\n\r\n\r\n\r\nA summary of the model below. “Sigma” is the standard deviation of the errors; “mean_PPD” is the mean of the posterior predictive samples.MCMC diagnostics - “RHat” is a measure of within chain variance compared to across chain variance (<1.1 implies convergence); “log-posterior” is similar to likelihood.\r\n\r\n\r\nShow code\r\n\r\nprint(summary(model_bayes_glm),digits=4)\r\n\r\n\r\n\r\nModel Info:\r\n function:     stan_glm\r\n family:       binomial [logit]\r\n formula:      PREVCHD ~ AGE + SEX + PREVHYP + DIABETES + TOTCHOL\r\n algorithm:    sampling\r\n sample:       6000 (posterior sample size)\r\n priors:       see help('prior_summary')\r\n observations: 2679\r\n predictors:   6\r\n\r\nEstimates:\r\n              mean    sd      10%     50%     90%  \r\n(Intercept) -7.7298  0.7574 -8.6881 -7.7214 -6.7675\r\nAGE          0.0866  0.0104  0.0733  0.0864  0.1001\r\nSEX         -1.0019  0.1685 -1.2184 -1.0005 -0.7836\r\nPREVHYP      0.5804  0.1804  0.3495  0.5792  0.8147\r\nDIABETES     0.8761  0.2749  0.5219  0.8810  1.2261\r\nTOTCHOL      0.0043  0.0018  0.0021  0.0043  0.0066\r\n\r\nFit Diagnostics:\r\n           mean   sd     10%    50%    90% \r\nmean_PPD 0.0663 0.0065 0.0579 0.0661 0.0747\r\n\r\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\r\n\r\nMCMC diagnostics\r\n              mcse   Rhat   n_eff\r\n(Intercept)   0.0103 1.0003 5423 \r\nAGE           0.0001 1.0002 5369 \r\nSEX           0.0024 1.0000 4800 \r\nPREVHYP       0.0023 1.0000 6192 \r\nDIABETES      0.0037 0.9995 5600 \r\nTOTCHOL       0.0000 0.9998 5269 \r\nmean_PPD      0.0001 0.9999 6254 \r\nlog-posterior 0.0327 0.9998 2764 \r\n\r\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\r\n\r\nThe stan model used default normal priors for intercepts and coefficients. Default priors are automatically scaled to limit how informative they are - below we can see the adjusted (scaled) prior for the coefficients differs from the default 2.5:\r\n\r\n\r\nShow code\r\n\r\n# summary of priors\r\nprint(prior_summary(model_bayes_glm),digits=4)\r\n\r\n\r\nPriors for model 'model_bayes_glm' \r\n------\r\nIntercept (after predictors centered)\r\n ~ normal(location = 0, scale = 2.5)\r\n\r\nCoefficients\r\n  Specified prior:\r\n    ~ normal(location = [0,0,0,...], scale = [2.5,2.5,2.5,...])\r\n  Adjusted prior:\r\n    ~ normal(location = [0,0,0,...], scale = [0.2960,5.0435,4.9991,...])\r\n------\r\nSee help('prior_summary.stanreg') for more details\r\n\r\nCredible intervals express the probability that a parameter falls within a given range (vs a confidence interval which is the probability that a range contains the true value of the parameter). These credible intervals are computed by finding the relevant quantiles of the draws from the posterior distribution. They produce similar ranges to the confidence intervals from the frequentist approach.\r\n\r\n\r\nShow code\r\n\r\nconfint(final_model_glm, level=0.95)\r\n\r\n\r\n                    2.5 %       97.5 %\r\n(Intercept) -9.2283366671 -6.245962073\r\nAGE          0.0663509219  0.107200545\r\nSEX         -1.3486617769 -0.672892414\r\nPREVHYP      0.2340626314  0.939831811\r\nDIABETES     0.3283690904  1.406163436\r\nTOTCHOL      0.0008633166  0.007741138\r\n\r\nShow code\r\n\r\nposterior_interval(model_bayes_glm, prob=0.95)\r\n\r\n\r\n                     2.5%        97.5%\r\n(Intercept) -9.2230488519 -6.236102853\r\nAGE          0.0662189510  0.106969391\r\nSEX         -1.3391722303 -0.679735717\r\nPREVHYP      0.2320658472  0.931637743\r\nDIABETES     0.3200214602  1.400848832\r\nTOTCHOL      0.0008553807  0.007827313\r\n\r\nAdjusting scales and changing priors\r\nstan_glm allows a selection of prior distributions for the coefficients, intercept, and auxiliary parameters. The prior distributions can be altered by specifying different locations/scales/dfs, but all the prior take the form of a single chosen probability distribution.\r\nSome drivers for wanting to specify a prior: * Available information/ research might suggest a base value for our parameters. Particularly valuable if our own observed data is sparse. * We may not have a good idea of the value, but know that it is constrained in some way e.g. is positive.\r\nThe scale is the standard deviation of the prior. As noted earlier, the model autoscales to ensure priors are not too informative. We can turn this off when we specify our own priors. Documentation on choice of priors is here.\r\nTo allow for varying distributions across the priors, we need to define the model in STAN or JAGS. See the linear regression example below for an example of this in JAGS.\r\nSpecifying our own priors below. Little impact on the posterior estimates.\r\n\r\n\r\nShow code\r\n\r\nmodel_bayes_glm_scale <- stan_glm(PREVCHD ~ AGE + SEX + PREVHYP + DIABETES + TOTCHOL, family = \"binomial\",data=df_heart_train, iter=2000, warmup=500,\r\n                            prior_intercept = normal(location = 0, scale = 10, autoscale = FALSE),\r\n                            prior = normal(location = 0, scale = 5, autoscale = FALSE),\r\n                            prior_aux = exponential(rate = 1, autoscale = FALSE)\r\n                            )\r\n\r\n\r\n\r\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 1).\r\nChain 1: \r\nChain 1: Gradient evaluation took 0 seconds\r\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r\nChain 1: Adjust your expectations accordingly!\r\nChain 1: \r\nChain 1: \r\nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\r\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\r\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\r\nChain 1: Iteration:  501 / 2000 [ 25%]  (Sampling)\r\nChain 1: Iteration:  700 / 2000 [ 35%]  (Sampling)\r\nChain 1: Iteration:  900 / 2000 [ 45%]  (Sampling)\r\nChain 1: Iteration: 1100 / 2000 [ 55%]  (Sampling)\r\nChain 1: Iteration: 1300 / 2000 [ 65%]  (Sampling)\r\nChain 1: Iteration: 1500 / 2000 [ 75%]  (Sampling)\r\nChain 1: Iteration: 1700 / 2000 [ 85%]  (Sampling)\r\nChain 1: Iteration: 1900 / 2000 [ 95%]  (Sampling)\r\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\r\nChain 1: \r\nChain 1:  Elapsed Time: 28.057 seconds (Warm-up)\r\nChain 1:                48.213 seconds (Sampling)\r\nChain 1:                76.27 seconds (Total)\r\nChain 1: \r\n\r\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 2).\r\nChain 2: \r\nChain 2: Gradient evaluation took 0 seconds\r\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r\nChain 2: Adjust your expectations accordingly!\r\nChain 2: \r\nChain 2: \r\nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\r\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\r\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\r\nChain 2: Iteration:  501 / 2000 [ 25%]  (Sampling)\r\nChain 2: Iteration:  700 / 2000 [ 35%]  (Sampling)\r\nChain 2: Iteration:  900 / 2000 [ 45%]  (Sampling)\r\nChain 2: Iteration: 1100 / 2000 [ 55%]  (Sampling)\r\nChain 2: Iteration: 1300 / 2000 [ 65%]  (Sampling)\r\nChain 2: Iteration: 1500 / 2000 [ 75%]  (Sampling)\r\nChain 2: Iteration: 1700 / 2000 [ 85%]  (Sampling)\r\nChain 2: Iteration: 1900 / 2000 [ 95%]  (Sampling)\r\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\r\nChain 2: \r\nChain 2:  Elapsed Time: 13.22 seconds (Warm-up)\r\nChain 2:                37.266 seconds (Sampling)\r\nChain 2:                50.486 seconds (Total)\r\nChain 2: \r\n\r\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 3).\r\nChain 3: \r\nChain 3: Gradient evaluation took 0 seconds\r\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\r\nChain 3: Adjust your expectations accordingly!\r\nChain 3: \r\nChain 3: \r\nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\r\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\r\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\r\nChain 3: Iteration:  501 / 2000 [ 25%]  (Sampling)\r\nChain 3: Iteration:  700 / 2000 [ 35%]  (Sampling)\r\nChain 3: Iteration:  900 / 2000 [ 45%]  (Sampling)\r\nChain 3: Iteration: 1100 / 2000 [ 55%]  (Sampling)\r\nChain 3: Iteration: 1300 / 2000 [ 65%]  (Sampling)\r\nChain 3: Iteration: 1500 / 2000 [ 75%]  (Sampling)\r\nChain 3: Iteration: 1700 / 2000 [ 85%]  (Sampling)\r\nChain 3: Iteration: 1900 / 2000 [ 95%]  (Sampling)\r\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\r\nChain 3: \r\nChain 3:  Elapsed Time: 15.146 seconds (Warm-up)\r\nChain 3:                50.725 seconds (Sampling)\r\nChain 3:                65.871 seconds (Total)\r\nChain 3: \r\n\r\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 4).\r\nChain 4: \r\nChain 4: Gradient evaluation took 0.001 seconds\r\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 10 seconds.\r\nChain 4: Adjust your expectations accordingly!\r\nChain 4: \r\nChain 4: \r\nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\r\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\r\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\r\nChain 4: Iteration:  501 / 2000 [ 25%]  (Sampling)\r\nChain 4: Iteration:  700 / 2000 [ 35%]  (Sampling)\r\nChain 4: Iteration:  900 / 2000 [ 45%]  (Sampling)\r\nChain 4: Iteration: 1100 / 2000 [ 55%]  (Sampling)\r\nChain 4: Iteration: 1300 / 2000 [ 65%]  (Sampling)\r\nChain 4: Iteration: 1500 / 2000 [ 75%]  (Sampling)\r\nChain 4: Iteration: 1700 / 2000 [ 85%]  (Sampling)\r\nChain 4: Iteration: 1900 / 2000 [ 95%]  (Sampling)\r\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\r\nChain 4: \r\nChain 4:  Elapsed Time: 25.191 seconds (Warm-up)\r\nChain 4:                36.979 seconds (Sampling)\r\nChain 4:                62.17 seconds (Total)\r\nChain 4: \r\n\r\nShow code\r\n\r\nprint(summary(model_bayes_glm_scale),digits=4)\r\n\r\n\r\n\r\nModel Info:\r\n function:     stan_glm\r\n family:       binomial [logit]\r\n formula:      PREVCHD ~ AGE + SEX + PREVHYP + DIABETES + TOTCHOL\r\n algorithm:    sampling\r\n sample:       6000 (posterior sample size)\r\n priors:       see help('prior_summary')\r\n observations: 2679\r\n predictors:   6\r\n\r\nEstimates:\r\n              mean    sd      10%     50%     90%  \r\n(Intercept) -7.7433  0.7623 -8.7048 -7.7397 -6.7708\r\nAGE          0.0869  0.0105  0.0739  0.0870  0.1001\r\nSEX         -1.0100  0.1733 -1.2341 -1.0096 -0.7919\r\nPREVHYP      0.5866  0.1756  0.3659  0.5859  0.8145\r\nDIABETES     0.8714  0.2721  0.5245  0.8741  1.2207\r\nTOTCHOL      0.0043  0.0017  0.0021  0.0044  0.0065\r\n\r\nFit Diagnostics:\r\n           mean   sd     10%    50%    90% \r\nmean_PPD 0.0661 0.0065 0.0579 0.0661 0.0743\r\n\r\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\r\n\r\nMCMC diagnostics\r\n              mcse   Rhat   n_eff\r\n(Intercept)   0.0103 1.0004 5488 \r\nAGE           0.0001 1.0007 5418 \r\nSEX           0.0027 1.0001 4179 \r\nPREVHYP       0.0030 1.0002 3324 \r\nDIABETES      0.0042 1.0000 4156 \r\nTOTCHOL       0.0000 1.0001 5451 \r\nmean_PPD      0.0001 1.0002 5316 \r\nlog-posterior 0.0359 1.0012 2340 \r\n\r\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\r\n\r\nModel fit\r\nWe are able to extract predictions from each iteration of the posterior sampling. We can extract predictions for new data. Could be tested against the observations for goodness of fit. The follwing from the manual, “RSTANARM Manual” (2020), p43:\r\n\r\n“The posterior predictive distribution (posterior_predict) is the distribution of the outcome implied by the model after using the observed data to update our beliefs about the unknown parameters in the model. Simulating data from the posterior predictive distribution using the observed predictors is useful for checking the fit of the model. Drawing from the posterior predictive distribution at interesting values of the predictors also lets us visualize how a manipulation of a predictor affects (a function of)the outcome(s). With new observations of predictor variables we can use the posterior predictive distribution to generate predicted outcomes.”\r\n\r\n\r\n\r\nShow code\r\n\r\nposteriors <- posterior_predict(model_bayes_glm,newdata=df_heart_test)\r\nposterior <- as.data.frame(posteriors) # each column is a data point from the dataset and each row is a prediction\r\n# Print 10 predictions for 5 lives\r\nprint(\"10 predictions for 5 lives\")\r\n\r\n\r\n[1] \"10 predictions for 5 lives\"\r\n\r\nShow code\r\n\r\nposteriors[1:10, 1:5]\r\n\r\n\r\n      8 12 16 23 33\r\n [1,] 0  0  0  0  0\r\n [2,] 0  0  0  0  0\r\n [3,] 0  0  0  0  0\r\n [4,] 0  0  0  0  0\r\n [5,] 0  0  0  0  0\r\n [6,] 0  0  0  0  0\r\n [7,] 0  0  0  0  0\r\n [8,] 0  0  1  0  0\r\n [9,] 0  0  0  0  0\r\n[10,] 0  0  0  0  0\r\n\r\nWe can plot the posterior distributions for the model parameters from the samples:\r\n\r\n\r\nShow code\r\n\r\nposterior <- as.matrix(model_bayes_glm)\r\n\r\nplot1<- mcmc_areas(posterior, pars = c(\"AGE\"), prob = 0.80)\r\nplot2<- mcmc_areas(posterior, pars = c(\"SEX\"), prob = 0.80)\r\nplot3<- mcmc_areas(posterior, pars = c(\"PREVHYP\"), prob = 0.80)\r\nplot4<- mcmc_areas(posterior, pars = c(\"DIABETES\"), prob = 0.80)\r\nplot5<- mcmc_areas(posterior, pars = c(\"TOTCHOL\"), prob = 0.80)\r\n\r\ngrid.arrange(plot1,plot2, plot3, plot4, plot5, top=\"Posterior distributions (median + 80% intervals)\")\r\n\r\n\r\n\r\n\r\nWe can extract the \\(R^2\\) from the posterior distribution and plot:\r\n\r\n\r\nShow code\r\n\r\nr2_posterior <- bayes_R2(model_bayes_glm)\r\nsummary(r2_posterior)\r\n\r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n0.03079 0.06487 0.07294 0.07373 0.08203 0.12257 \r\n\r\nShow code\r\n\r\nhist(r2_posterior) #expect normal\r\n\r\n\r\n\r\n\r\nPosterior predictive checks can be extracted using “pp_check”\r\n“dens_overlay” - each light blue line represents the distribution of predicted scores from a single replication, and the dark blue line represents the observed data. If the model fits, the dark blue line should align closely with the light blue lines.\r\n“stat” in the “pp_check” function, we can get a distribution of the mean of the dependent variable from all replications. These are the light blue bars: the means from each replication plotted as a histogram. The mean from the observed data is then plotted on top as a dark blue bar.\r\nHere the outcome is binary so the density overlay outcomes are concentrated at one or zero.\r\n\r\n\r\nShow code\r\n\r\npp_check(model_bayes_glm, \"stat\")\r\n\r\n\r\n\r\nShow code\r\n\r\npp_check(model_bayes_glm, \"dens_overlay\")\r\n\r\n\r\n\r\n\r\nFurther considerations: The loo package provides “efficient approximate leave-one-out cross-validation (LOO), approximate standard errors for estimated predictive errors (including comparisons), and the widely applicable information criterion (WAIC).The loo package can be used to estimate predictive error of any MCMC item-level log likelihood output.”\r\nRegression - linear\r\nThe above example looked at a binary response. In this example we’ll look at predicting a continuous variable using data on my household electricity consumption over 2016-2021. The above example used stan_glm in RSTANARM. Here we will use a model defined in RJAGS with additional flexibility around the choice of priors, which is also possible in a paramaterised model for STAN. RJAGS combines the power of R with the “Just Another Gibbs Sampler” or “JAGS” engine. To get started, first download the “JAGS” program, then set up the packages as above.\r\nBoth JAGS and STAN allow for the parameterisation of a range of different models. The example below was chosen for comparison with a conventional GLM approach.\r\nData prep:\r\nDaily electricity usage for a household in Sydney over 2019-21. Rows represent half hourly readings/ estimates.\r\nData are grouped into daily usage.\r\nAlso includes are temperatures, sunlight and rainfall data for the area taken from BOM.\r\nCalculated fields for weekdays vs weekends, seasons and a post-covid working from home indicator.\r\n\r\n\r\nShow code\r\n\r\ndf_usage <- read.csv(file = 'elec_usage.csv')\r\ndf_usage <- df_usage %>% mutate(Date = as.Date(Date, format=\"%Y-%m-%d\"), EndDate = parse_date_time(EndDate, '%Y-%m-%d %H:%M:%S'), StartDate = parse_date_time(StartDate, '%Y-%m-%d %H:%M:%S'))\r\ndf_usage <- df_usage[c(-2,-3,-4,-6)] %>% # drop start and end dates, rate type, duration\r\ngroup_by(Date) %>% summarise(Usage = sum(Usage), MaxTemp = max(MaxTemp), MinTemp = min(MinTemp), Rain_mm = max(Rain_mm), Solar_Exposure = max(Solar_Exposure)) %>%\r\n# Add in fields to identify seasons, weekend/ weekday and an indicator for the post-covid/ work from home period\r\nmutate(Season=\r\n  if_else(month(Date)>= 3 & month(Date) < 6,\"Autumn\", \r\n  if_else(month(Date)>= 6 & month(Date) < 9,\"Winter\", \r\n  if_else(month(Date)>= 9 & month(Date) < 12,\"Spring\",\"Summer\"))),\r\nCovid_Ind=if_else(Date>= \"2020-03-15\",1,0),\r\nWeekend=\r\n  if_else(wday(Date)==7 | wday(Date)==1,1,0))\r\n\r\ndf_usage$Season <- factor(df_usage$Season, levels = c(\"Summer\",\"Autumn\",\"Winter\",\"Spring\")) # change season levels\r\n\r\nhead(df_usage)\r\n\r\n\r\n# A tibble: 6 x 9\r\n  Date       Usage MaxTemp MinTemp Rain_mm Solar_Exposure Season\r\n  <date>     <dbl>   <dbl>   <dbl>   <dbl>          <dbl> <fct> \r\n1 2019-12-21 21.1     26.7    21       0             27.1 Summer\r\n2 2019-12-22  9.53    19.9    18.6     0             11.9 Summer\r\n3 2019-12-23 15.7     22.1    17.2     0             14.4 Summer\r\n4 2019-12-24 18.7     24      18.6     1.8           18.3 Summer\r\n5 2019-12-25 18.9     23.2    21.6     0.2           27.8 Summer\r\n6 2019-12-26 14.6     23.6    21.4     0             30.8 Summer\r\n# ... with 2 more variables: Covid_Ind <dbl>, Weekend <dbl>\r\n\r\nData is mostly complete:\r\n\r\n\r\nShow code\r\n\r\nintroduce(df_usage)\r\n\r\n\r\n# A tibble: 1 x 9\r\n   rows columns discrete_columns continuous_columns all_missing_colum~\r\n  <int>   <int>            <int>              <int>              <int>\r\n1   732       9                2                  7                  0\r\n# ... with 4 more variables: total_missing_values <int>,\r\n#   complete_rows <int>, total_observations <int>, memory_usage <dbl>\r\n\r\nShow code\r\n\r\nplot_intro(df_usage)\r\n\r\n\r\n\r\nShow code\r\n\r\nplot_missing(df_usage)\r\n\r\n\r\n\r\n\r\nDrop records with NAs as they are few, also only include non-zero usage, review explanatory variables; Gamma dist potentially a better fit than normal for Usage given the skewness in the tail; alternatively use normal with a log link.\r\n\r\n\r\nShow code\r\n\r\ndf_usage <- na.omit(df_usage)\r\ndf_usage <- df_usage %>% filter(Usage>0)\r\n\r\nplot_bar(df_usage, title=\"Barplot\")\r\n\r\n\r\n\r\nShow code\r\n\r\nplot_histogram(df_usage, title=\"Histogram for continuous\")\r\n\r\n\r\n\r\nShow code\r\n\r\nqq_data <- df_usage[,c(\"MaxTemp\", \"MinTemp\", \"Solar_Exposure\", \"Usage\")]\r\nplot_qq(qq_data, title=\"QQ plot\")\r\n\r\n\r\n\r\nShow code\r\n\r\nlog_qq_data <- update_columns(qq_data, 2:4, function(x) log(x + 1))\r\nplot_qq(log_qq_data, title=\"QQ plot, logged data\")\r\n\r\n\r\n\r\nShow code\r\n\r\nusage_fit_gamma <- fitdist(df_usage$Usage, distr = \"gamma\", method = \"mme\")\r\nsummary(usage_fit_gamma)\r\n\r\n\r\nFitting of the distribution ' gamma ' by matching moments \r\nParameters : \r\n       estimate\r\nshape 2.9114935\r\nrate  0.1164095\r\nLoglikelihood:  -2813.89   AIC:  5631.78   BIC:  5640.902 \r\n\r\nShow code\r\n\r\nplot(usage_fit_gamma)\r\n\r\n\r\n\r\n\r\nUsage correlated with season, max/min temp and covid wfh indicator. Max and Min Temps are not surprisingly highly correlated with one another, with the seasons and with solar exposure.\r\n\r\n\r\nShow code\r\n\r\nplot_correlation(na.omit(df_usage))\r\n\r\n\r\n\r\n\r\nSplit data into training and testing data sets:\r\n\r\n\r\nShow code\r\n\r\n# Create a random sample of row IDs\r\nsample_rows <- sample(nrow(df_usage),0.75*nrow(df_usage))\r\n# Create the training dataset\r\ndf_usage_train <- df_usage[sample_rows,]\r\n# Create the test dataset\r\ndf_usage_test <- df_usage[-sample_rows,]\r\n\r\n\r\n\r\nFit a simple GLM using all variables:\r\n\r\n\r\nShow code\r\n\r\nfull_model_glm <- glm(Usage~.,data=df_usage_train[-1], gaussian(link=\"log\"))\r\nsummary(full_model_glm)\r\n\r\n\r\n\r\nCall:\r\nglm(formula = Usage ~ ., family = gaussian(link = \"log\"), data = df_usage_train[-1])\r\n\r\nDeviance Residuals: \r\n    Min       1Q   Median       3Q      Max  \r\n-47.071   -4.237    0.038    4.310   50.085  \r\n\r\nCoefficients:\r\n                 Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept)     5.2454260  0.1912374  27.429  < 2e-16 ***\r\nMaxTemp        -0.0127523  0.0084359  -1.512   0.1312    \r\nMinTemp        -0.1052054  0.0091383 -11.513  < 2e-16 ***\r\nRain_mm         0.0000787  0.0013484   0.058   0.9535    \r\nSolar_Exposure -0.0182197  0.0037327  -4.881 1.41e-06 ***\r\nSeasonAutumn    0.0106473  0.0844629   0.126   0.8997    \r\nSeasonWinter    0.0397571  0.0940844   0.423   0.6728    \r\nSeasonSpring    0.0449831  0.0848165   0.530   0.5961    \r\nCovid_Ind       0.0188646  0.1024498   0.184   0.8540    \r\nWeekend        -0.0757548  0.0326541  -2.320   0.0207 *  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n(Dispersion parameter for gaussian family taken to be 83.40396)\r\n\r\n    Null deviance: 118334  on 529  degrees of freedom\r\nResidual deviance:  43368  on 520  degrees of freedom\r\nAIC: 3860.5\r\n\r\nNumber of Fisher Scoring iterations: 8\r\n\r\nUse stepwise regression to reduce the explanatory variables:\r\n\r\n\r\nShow code\r\n\r\n# specify a null model with no predictors\r\nnull_model_glm <- glm(Usage ~ 1, data = df_usage_train, gaussian(link=\"log\"))\r\n# use a forward stepwise algorithm to build a parsimonious model\r\nstep_model_glm <- step(null_model_glm, scope = list(lower = null_model_glm, upper = full_model_glm), direction = \"forward\")\r\n\r\n\r\n\r\nSummary of the model:\r\n\r\n\r\nShow code\r\n\r\nsummary(step_model_glm)\r\n\r\n\r\n\r\nCall:\r\nglm(formula = Usage ~ MinTemp + Solar_Exposure + Weekend + MaxTemp, \r\n    family = gaussian(link = \"log\"), data = df_usage_train)\r\n\r\nDeviance Residuals: \r\n    Min       1Q   Median       3Q      Max  \r\n-47.413   -4.231   -0.073    4.377   49.935  \r\n\r\nCoefficients:\r\n                Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept)     5.342228   0.094395  56.594  < 2e-16 ***\r\nMinTemp        -0.106992   0.006867 -15.580  < 2e-16 ***\r\nSolar_Exposure -0.017637   0.003222  -5.473 6.85e-08 ***\r\nWeekend        -0.075902   0.032433  -2.340   0.0196 *  \r\nMaxTemp        -0.014389   0.008022  -1.794   0.0734 .  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n(Dispersion parameter for gaussian family taken to be 82.73176)\r\n\r\n    Null deviance: 118334  on 529  degrees of freedom\r\nResidual deviance:  43434  on 525  degrees of freedom\r\nAIC: 3851.3\r\n\r\nNumber of Fisher Scoring iterations: 7\r\n\r\nFor simplicity, we’ll assume a model defined by MaxTemp and MinTemp only, noting the significant correlation with other explanatory variables.\r\n\r\n\r\nShow code\r\n\r\ngamma_model_glm <- glm(Usage ~ MaxTemp + MinTemp, family = Gamma(link=\"inverse\"), data = df_usage_train)\r\nsummary(final_model_glm)\r\n\r\n\r\n\r\nCall:\r\nglm(formula = PREVCHD ~ AGE + SEX + PREVHYP + DIABETES + TOTCHOL, \r\n    family = \"binomial\", data = df_heart_train)\r\n\r\nDeviance Residuals: \r\n    Min       1Q   Median       3Q      Max  \r\n-1.1777  -0.4060  -0.2705  -0.1810   2.9478  \r\n\r\nCoefficients:\r\n             Estimate Std. Error z value Pr(>|z|)    \r\n(Intercept) -7.712317   0.760024 -10.147  < 2e-16 ***\r\nAGE          0.086480   0.010409   8.308  < 2e-16 ***\r\nSEX         -1.006858   0.172141  -5.849 4.94e-09 ***\r\nPREVHYP      0.580990   0.179689   3.233  0.00122 ** \r\nDIABETES     0.887841   0.273721   3.244  0.00118 ** \r\nTOTCHOL      0.004345   0.001753   2.479  0.01318 *  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n(Dispersion parameter for binomial family taken to be 1)\r\n\r\n    Null deviance: 1303.9  on 2678  degrees of freedom\r\nResidual deviance: 1147.3  on 2673  degrees of freedom\r\nAIC: 1159.3\r\n\r\nNumber of Fisher Scoring iterations: 6\r\n\r\nChanging the family to gaussian with log link (later graph shows little change in predictions, although AIC is higher). Select gaussian for ease of comparison with the Bayes model.\r\n\r\n\r\nShow code\r\n\r\nfinal_model_glm <- glm(Usage ~ MaxTemp + MinTemp, family = gaussian(link=\"log\"), data = df_usage_train)\r\nsummary(final_model_glm)\r\n\r\n\r\n\r\nCall:\r\nglm(formula = Usage ~ MaxTemp + MinTemp, family = gaussian(link = \"log\"), \r\n    data = df_usage_train)\r\n\r\nDeviance Residuals: \r\n    Min       1Q   Median       3Q      Max  \r\n-51.771   -4.422   -0.142    4.276   48.199  \r\n\r\nCoefficients:\r\n             Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept)  5.336485   0.098274  54.302  < 2e-16 ***\r\nMaxTemp     -0.030072   0.007849  -3.831 0.000143 ***\r\nMinTemp     -0.102717   0.007149 -14.368  < 2e-16 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n(Dispersion parameter for gaussian family taken to be 88.24294)\r\n\r\n    Null deviance: 118334  on 529  degrees of freedom\r\nResidual deviance:  46504  on 527  degrees of freedom\r\nAIC: 3883.5\r\n\r\nNumber of Fisher Scoring iterations: 6\r\n\r\nExtract coefficients:\r\n\r\n\r\nShow code\r\n\r\nfinal_model_glm_coeff <- as.data.frame(coef(final_model_glm))\r\nfinal_model_glm_coeff\r\n\r\n\r\n            coef(final_model_glm)\r\n(Intercept)            5.33648506\r\nMaxTemp               -0.03007202\r\nMinTemp               -0.10271706\r\n\r\nProject the result for a dummy record showing the link:\r\n\r\n\r\nShow code\r\n\r\nprint(\"Dummy prediction with min of 10 and max of 20:\")\r\n\r\n\r\n[1] \"Dummy prediction with min of 10 and max of 20:\"\r\n\r\nShow code\r\n\r\npredict(final_model_glm, newdata= as.data.frame(cbind(MaxTemp=20,MinTemp=10)), # model and data\r\n  type=\"response\", # or terms for coefficients\r\n  se.fit = FALSE)\r\n\r\n\r\n       1 \r\n40.76705 \r\n\r\nShow code\r\n\r\n# replicate\r\nexp(final_model_glm_coeff[1,] + final_model_glm_coeff[2,]*20+final_model_glm_coeff[3,]*10)\r\n\r\n\r\n[1] 40.76705\r\n\r\nAdding the predictions to the test data:\r\n\r\n\r\nShow code\r\n\r\n# predictions, normal\r\npred_usage <- as.data.frame(\r\n  predict(final_model_glm, newdata= df_usage_test, # model and data\r\n  type=\"response\", # or terms for coefficients\r\n  se.fit = TRUE, # default is false\r\n  interval = \"confidence\", #default \"none\", also \"prediction\"\r\n  level = 0.95\r\n  )\r\n)\r\n\r\n# predictions, gamma\r\nusage_pred_gamma <- \r\n  predict(gamma_model_glm, newdata= df_usage_test, # model and data\r\n  type=\"response\", # or terms for coefficients\r\n  se.fit = FALSE, # default is false\r\n  )\r\n\r\n# rename\r\npred_usage <- rename(pred_usage,usage_pred=fit,se_usage_pred=se.fit)\r\n\r\n# add back to data\r\ndf_usage_test_pred <- cbind(df_usage_test,pred_usage, usage_pred_gamma)\r\n\r\n\r\n\r\nPlotting the results shows a poorer fit for winter when the usage spikes and in instances with outlier temperatures. Predictions for the test data are not hugely different to the gamma family model.\r\n\r\n\r\nShow code\r\n\r\ndf_usage_test_pred  %>%\r\nggplot() +\r\ngeom_point(aes(x=Date,y=Usage,color=Season)) +\r\n# add a modeled line\r\ngeom_line(aes(x=Date,y=usage_pred)) +\r\ngeom_line(aes(x=Date,y=usage_pred_gamma), linetype = \"dashed\") +\r\nlabs(x=\"Date\", y=\"Usage\", title = \"Actual vs predicted usage by date and season\",subtitle=\"Dashed=Gamma Pred; Solid=Normal Pred\") +\r\ntheme_pander() + scale_color_gdocs()\r\n\r\n\r\n\r\nShow code\r\n\r\n# plot temperatures\r\ndf_usage_test_pred  %>%\r\nggplot() +\r\ngeom_point(aes(x=Date,y=MaxTemp,color=Season)) + \r\nlabs(x=\"Date\", y=\"Usage\", title = \"MaxTemp by date and season\") +\r\ntheme_pander() + scale_color_gdocs()\r\n\r\n\r\n\r\n\r\nPlots show slightly higher residuals at higher predicted values for the step regression model and final selected. QQ plot suggests skewness in the data, which we could see earlier in the histogram of usage.\r\n\r\n\r\nShow code\r\n\r\npar(mfrow = c(2, 2))\r\nplot(final_model_glm)\r\n\r\n\r\n\r\nShow code\r\n\r\nplot(step_model_glm)\r\n\r\n\r\n\r\n\r\nDefine a regression model in RJAGS. The structure here is more flexible than stan_glm which is predefined. This allows for a wider selection of prior distributions and a mixture of modeling choices. Also possible to specify model forms in this way for STAN.\r\n\\(Y_i \\propto N(m_i,s^2)\\)\r\nWhere\r\n\\(m_i = a + bX_1i +cX_2i\\)\r\n\\(a, b, c and s\\) have some assumed prior distributions.\r\nNote that the distribution syntax is slightly different to R, for example in R a normal distribution is specified using the mean and standard deviation, but in JAGS the second parameter of the dnorm command is the distribution’s precision (1 / variance).\r\n\r\n\r\nShow code\r\n\r\nusage_model <- \"model{\r\n  #Likelihood model for Y[i]\r\n  for (i in 1:length(Y)) {\r\n      Y[i] ~ dnorm(m[i], s^(-2)) # link=log\r\n      log(m[i]) <- a + b*X_1[i] + c*X_2[i]\r\n  }\r\n\r\n  # Prior models for a, b, c, s\r\n  a ~ dnorm(0, 0.001)     # Intercept\r\n  b ~ dnorm(0, 0.001)     # MaxTemp\r\n  c ~ dnorm(0, 0.001)     # MinTemp\r\n  s ~ dunif(0, 10)        # Error\r\n\r\n}\"\r\n\r\n\r\n\r\nSimulate from the model:\r\nburn-in period of 2k iterations aims for convergence and throws away these earlier test samples.\r\n10k iterations for 3 chains.\r\nsaving every 10th sample only in order to save space.\r\n\r\n\r\nShow code\r\n\r\nusage_sim <- jags.model(textConnection(usage_model),\r\n              data=list(Y = df_usage_train$Usage, X_1 = df_usage_train$MaxTemp, X_2 = df_usage_train$MinTemp),\r\n              n.chains = 3)\r\n\r\n\r\nCompiling model graph\r\n   Resolving undeclared variables\r\n   Allocating nodes\r\nGraph information:\r\n   Observed stochastic nodes: 530\r\n   Unobserved stochastic nodes: 4\r\n   Total graph size: 3456\r\n\r\nInitializing model\r\n\r\nShow code\r\n\r\nusage_posterior <- coda.samples(usage_sim, \r\n                                 variable.names = c(\"a\",\"b\",\"c\",\"s\"), \r\n                                 n.iter = 10000, n.burnin = 2000, n.thin = 10, DIC = F)\r\n\r\n\r\n\r\nSummary of the results below:\r\nThe mean of the b chain value was -0.040. This is an estimate of the posterior mean of b. This is consistent with the GLM above\r\nThe corresponding naive standard error, 0.000253, measures the potential error in this estimate. This error is calculated by dividing the standard deviation of the b chain values by the square root of the number of iterations (or sample size). This is a naive approach to calculating error in a setting with dependent samples.\r\nThe density plots for\r\n\r\n\r\nShow code\r\n\r\nsummary(usage_posterior)\r\n\r\n\r\n\r\nIterations = 1001:11000\r\nThinning interval = 1 \r\nNumber of chains = 3 \r\nSample size per chain = 10000 \r\n\r\n1. Empirical mean and standard deviation for each variable,\r\n   plus standard error of the mean:\r\n\r\n      Mean       SD  Naive SE Time-series SE\r\na  5.34249 0.099682 5.755e-04      0.0062062\r\nb -0.03071 0.007912 4.568e-05      0.0007325\r\nc -0.10233 0.007230 4.174e-05      0.0004389\r\ns  9.39676 0.269467 1.556e-03      0.0019669\r\n\r\n2. Quantiles for each variable:\r\n\r\n      2.5%      25%      50%      75%    97.5%\r\na  5.14616  5.27658  5.34314  5.41043  5.53213\r\nb -0.04588 -0.03606 -0.03062 -0.02546 -0.01508\r\nc -0.11672 -0.10701 -0.10237 -0.09762 -0.08821\r\ns  8.86382  9.21007  9.39916  9.58982  9.90192\r\n\r\nShow code\r\n\r\nplot(usage_posterior,trace=FALSE)\r\n\r\n\r\n\r\nShow code\r\n\r\npar(mfrow = c(2, 2))\r\nplot(usage_posterior,density=FALSE)\r\n\r\n\r\n\r\n\r\nWe can plot the posterior distributions for the model parameters from the samples:\r\n\r\n\r\nShow code\r\n\r\nposterior <- as.matrix(usage_posterior)\r\n\r\nplot1<- mcmc_areas(posterior, pars = c(\"a\"), prob = 0.80)\r\nplot2<- mcmc_areas(posterior, pars = c(\"b\"), prob = 0.80)\r\nplot3<- mcmc_areas(posterior, pars = c(\"c\"), prob = 0.80)\r\nplot4<- mcmc_areas(posterior, pars = c(\"s\"), prob = 0.80)\r\n\r\ngrid.arrange(plot1,plot2, plot3, plot4, top=\"Posterior distributions (median + 80% intervals)\")\r\n\r\n\r\n\r\n\r\nSimilar to the earlier example, we could extract the \\(R^2\\) from the posterior distribution as well as run posterior predictive checks.\r\nFurther considerations: extracting the mean of the parameter projections, we could produce predictions for the test data. We could also produce predictions for test data point based upon each of the samples from the posterior, so above we would produce 2400 predictions for each data point (3x10k, discarding the first 2k from each chain and only saving 1/10 of the samples).\r\nEstimating COVID 19 infections in NSW, Australia\r\nHugh Miller, Isabella Lyons (2012) discusses a method of forecasting COVID infections using the package “epinow2”, Sam Abbott (2020). The package makes use of STAN.\r\n\r\n“[Epinow2] estimates the time-varying reproduction number on cases by date of infection… Imputed infections are then mapped to observed data (for example cases by date of report) via a series of uncertain delay distributions…”\r\n\r\nThat is to say, the model makes some assumptions about lags in symptoms and in reporting (assuming some distribution for those delays) in order to estimate the true underlying number of infections (backwards). Using that backcast it projects out how those infections might be reported over time. The model also estimates the effective reproduction number in order to predict future infections.\r\nCovid case and test data sourced from the department of NSW Website on 17/01/2022. Cases:\r\n\r\n\r\nShow code\r\n\r\ndf_cases <- read.csv(file = 'confirmed_cases_table1_location.csv') \r\nhead(df_cases)\r\n\r\n\r\n  notification_date postcode lhd_2010_code        lhd_2010_name\r\n1        2020-01-25     2134          X700               Sydney\r\n2        2020-01-25     2121          X760      Northern Sydney\r\n3        2020-01-25     2071          X760      Northern Sydney\r\n4        2020-01-27     2033          X720 South Eastern Sydney\r\n5        2020-03-01     2077          X760      Northern Sydney\r\n6        2020-03-01     2163          X710 South Western Sydney\r\n  lga_code19      lga_name19\r\n1      11300     Burwood (A)\r\n2      16260  Parramatta (C)\r\n3      14500 Ku-ring-gai (A)\r\n4      16550    Randwick (C)\r\n5      14000     Hornsby (A)\r\n6      12850   Fairfield (C)\r\n\r\nShow code\r\n\r\ndf_tests <- read.csv(file = 'pcr_testing_table1_location_agg.csv') \r\nhead(df_tests)\r\n\r\n\r\n   test_date postcode lhd_2010_code   lhd_2010_name lga_code19\r\n1 2020-01-01     2038          X700          Sydney      14170\r\n2 2020-01-01     2039          X700          Sydney      14170\r\n3 2020-01-01     2040          X700          Sydney      14170\r\n4 2020-01-01     2041          X700          Sydney      14170\r\n5 2020-01-01     2069          X760 Northern Sydney      14500\r\n6 2020-01-01     2074          X760 Northern Sydney      14500\r\n       lga_name19 test_count\r\n1  Inner West (A)          1\r\n2  Inner West (A)          1\r\n3  Inner West (A)          2\r\n4  Inner West (A)          1\r\n5 Ku-ring-gai (A)          1\r\n6 Ku-ring-gai (A)          1\r\n\r\nShow code\r\n\r\n# cases\r\ndf_cases <- df_cases %>% mutate(descr=\"cases\",date=as.Date(notification_date),cases=1) %>%\r\nfilter(date > \"2021-04-30\",date <= \"2021-12-31\") %>% \r\ngroup_by(date, descr) %>% \r\nsummarise(confirm=sum(cases)) \r\nhead(df_cases)\r\n\r\n\r\n# A tibble: 6 x 3\r\n# Groups:   date [6]\r\n  date       descr confirm\r\n  <date>     <chr>   <dbl>\r\n1 2021-05-01 cases       2\r\n2 2021-05-02 cases       8\r\n3 2021-05-03 cases       9\r\n4 2021-05-04 cases       7\r\n5 2021-05-05 cases       9\r\n6 2021-05-06 cases       4\r\n\r\nPlotting recorded cases by date (PCR test outcomes only and only to 31 December 2021):\r\n\r\n\r\nShow code\r\n\r\ndf_cases %>% mutate(omicron=ifelse(date > \"2021-11-26\",\"first case+\",\"pre\")) %>%\r\nggplot(data=., mapping = aes(x=date, y=confirm)) + \r\ngeom_col(aes(fill=omicron)) +\r\nscale_x_date(date_breaks = \"months\" , date_labels = \"%b-%y\", limits = c(as.Date(\"2021-04-30\"), as.Date(\"2021-12-31\"))) +\r\nlabs(x=\"Date\", y=\"Cases\", title = \"Covid cases by date, NSW\") +\r\ntheme_pander() + scale_color_gdocs()\r\n\r\n\r\n\r\n\r\nTest data:\r\n\r\n\r\nShow code\r\n\r\ndf_tests <- df_tests %>% mutate(descr=\"tests\",date=as.Date(test_date)) %>%\r\nfilter(date > \"2021-04-30\",date <= \"2021-12-31\") %>% \r\ngroup_by(date, descr) %>% \r\nsummarise(tests=sum(test_count)) \r\nhead(df_tests)\r\n\r\n\r\n# A tibble: 6 x 3\r\n# Groups:   date [6]\r\n  date       descr tests\r\n  <date>     <chr> <int>\r\n1 2021-05-01 tests  4514\r\n2 2021-05-02 tests  4775\r\n3 2021-05-03 tests 14877\r\n4 2021-05-04 tests 10868\r\n5 2021-05-05 tests 13126\r\n6 2021-05-06 tests 24029\r\n\r\nPlotting tests by date (PCR tests only; to 31 December 2021):\r\n\r\n\r\nShow code\r\n\r\nggplot(data=df_tests, mapping = aes(x=date, y=tests))+ \r\ngeom_bar(stat=\"identity\") +\r\nscale_x_date(date_breaks = \"months\" , date_labels = \"%b-%y\", limits = c(as.Date(\"2021-04-30\"), as.Date(\"2021-12-31\"))) +\r\nlabs(x=\"Date\", y=\"Tests\", title = \"PCR tests by date, NSW\") +\r\ntheme_pander() + scale_color_gdocs()\r\n\r\n\r\n\r\n\r\nMerged to get positive test rate:\r\n\r\n\r\nShow code\r\n\r\n# merge\r\ndf <- merge(x = df_cases, y = df_tests, by = \"date\", all.x = TRUE) %>%\r\nmutate(pos_rate=pmin(1, confirm/tests)) %>%\r\nfill(pos_rate, .direction = \"downup\") %>%\r\n# add smoothed positive rate\r\nmutate(pos_rate_sm = fitted(loess(pos_rate~as.numeric(date),span=0.1))) # loess - Local Polynomial Regression Fitting; span - the parameter which controls the degree of smoothing\r\n# drop descriptions\r\ndf$descr.x <- NULL\r\ndf$descr.y <- NULL\r\n\r\n\r\n\r\nPlot of positive rate shows that the proportion of tests returning a positive increases to above 5% from 25th December 2021, suggesting that the case data beyond this point is less complete.\r\n\r\n\r\nShow code\r\n\r\n# positive rate\r\nggplot(data=df, mapping = aes(x=date))+ \r\ngeom_point(aes(y=(pos_rate))) +\r\ngeom_line(aes(y=pos_rate_sm)) +\r\nscale_x_date(date_breaks = \"months\" , date_labels = \"%b-%y\", limits = c(as.Date(\"2021-04-30\"), as.Date(\"2021-12-31\"))) +\r\nscale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\r\nlabs(x=\"Date\", y=\"Positive test rate\", title = \"Positive PCR test rate by date, NSW\") +\r\ntheme_pander() + scale_color_gdocs()\r\n\r\n\r\n\r\n\r\nThere are some pragmatic methods for adjusting the case numbers for increasing test positivity rates. For our purposes we will focus the model on case data before 23 December 2021 in order to exclude the period where the test data became less reliable/ complete.\r\n\r\n\r\nShow code\r\n\r\n# Reporting delays (delay from symptom onset to reporting/ testing positive)\r\nreporting_delay <- estimate_delay(rlnorm(100, log(6), 1), max_value = 15)\r\ncat(\"Mean reporting delay = \",reporting_delay$mean, \"; \")\r\n\r\n# Symptom generation time (time between infection events in an infector-infectee pair) and incubation period (time between moment of infection and symptom onset)\r\ngeneration_time <- get_generation_time(disease = \"SARS-CoV-2\", source = \"ganyani\")\r\ncat(\"Mean generation time =\",generation_time$mean, \"; \")\r\nincubation_period <- get_incubation_period(disease = \"SARS-CoV-2\", source = \"lauer\")\r\ncat(\"Mean incubation period =\",incubation_period$mean, \"; \")\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\ndf_cases_fit <- df_cases %>% filter(date <= \"2021-12-22\") # exclude data before 23 December 2021\r\n\r\nestimates <- epinow(reported_cases = df_cases_fit[c(\"date\",\"confirm\")], # case data from NSW\r\n                    generation_time = generation_time,\r\n                    delays = delay_opts(incubation_period, reporting_delay),\r\n                    rt = rt_opts(prior = list(mean = 2, sd = 0.2)),\r\n                    stan = stan_opts(cores = 6, samples = 3000, warmup = 500, chains = 6, control = list(adapt_delta = 0.95)))\r\n\r\n\r\n\r\nImporting a previous run of the above:\r\n\r\n\r\nShow code\r\n\r\nload(\"covid_estimates_summary.RData\")\r\n\r\n\r\n\r\nplot(estimates) produces predefined plots of cases by date reported and date of infection as well as the effective reproduction number. Given the dramatic increase in reported cases towards the end of the period, it is not surprising that the range of forecast cases is wide. Interestingly, the forecast/ partial forecast reproduction number reduces; presumably this is influenced by the earlier observations where case numbers were low. This issue has not been investigated further, however there are articles that discuss the impact of changes to the testing procedures and other limitations.\r\n Merging forecast reported cases with the actual case data:\r\n\r\n\r\nShow code\r\n\r\ndf <- merge(x = df, y = df_reported, by = \"date\", all.x = TRUE) %>% filter(date < \"2021-12-30\")\r\n\r\n\r\n\r\nPlotting forecast vs actuals below - the week to 29 December is fully forecast from the model. Actual cases fall within the projected 90% confidence interval range, noting that the test positivity rate increased materially from 25th December so it is likely that the actual cases are under reported.\r\n\r\n\r\nShow code\r\n\r\ncolours <- c(\"actual\" = \"#3366cc\",\"modelled\" = \"#dc3912\")\r\n\r\nggplot(data=df %>% filter(date >= \"2021-12-01\"), aes(x=date)) +\r\ngeom_line(aes(y=confirm, color=\"actual\")) +\r\ngeom_line(aes(y=mean,color=\"modelled\")) +\r\ngeom_ribbon(aes(ymin=lower_90, ymax=upper_90), fill=\"#dc3912\", alpha=0.2) +\r\nlabs(x=\"Date\", y=\"Reported cases\", title = \"Reported cases by date\",color=\"Legend\") +\r\nscale_color_manual(values = colours) +\r\ntheme_pander()\r\n\r\n\r\n\r\n\r\nCommon issues in MCMC projections\r\nDivergent transitions: Common fix is changing the step size using the adapt_delta argument in STAN.\r\nExceeding maximum tree depth: the is a point of efficiency. See notes here for assistance in STAN and other potential warnings.\r\nFurther reading\r\nA few books and articles of interest on STAN:\r\nSTAN documentation\r\nSTAN linear regression model\r\nApplied Bayesian Inference in r using STAN\r\nPrior selections - STAN package\r\nJAGS user manual\r\n\r\n\r\n\r\nHugh Miller, Isabella Lyons. 2012. “Grasping at the Invisible – Bayesian Models for Estimating Latent Economic Variables.” Australia. https://actuaries.logicaldoc.cloud/download-ticket?ticketId=4fda7653-5e3d-4514-a79f-ed0070a0f9be.\r\n\r\n\r\n“Mental Health and Insurance.” 2017. https://www.actuaries.asn.au/Library/Miscellaneous/2017/GPMENTALHEALTHWEBRCopy.pdf.\r\n\r\n\r\n———. 2020. Productivity Commission Inquiry Report 2. https://www.pc.gov.au/inquiries/completed/mental-health/report/mental-health-volume2.pdf.\r\n\r\n\r\n“RSTANARM Manual.” 2020. https://cran.r-project.org/web/packages/rstanarm/rstanarm.pdf.\r\n\r\n\r\nSam Abbott, Katharine Sherratt, Joel Hellewell. 2020. “EpiNow2: Estimate Real-Time Case Counts and Time-Varying Epidemiological Parameters.” https://doi.org/10.5281/zenodo.3957489.\r\n\r\n\r\nWilliam H. Press, William T. Vetterling, Saul A. Teukolsky. 2007. Numierical Recipes, Third Edition. New York: Cambridge University Press.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-02-01-bayesian-applications/distill-preview.png",
    "last_modified": "2022-01-21T15:19:23+11:00",
    "input_file": "bayesian-applications.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  }
]
